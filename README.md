## Customer Churn Prediction â€“ MLOps Pipeline

This project implements a complete **MLOps pipeline** for customer churn prediction using structured telco data. It manages the full lifecycle of a machine learning model â€” from preprocessing and training to deployment and inference via API.

---

## Technologies Used

| Component          | Tool                |
|--------------------|---------------------|
| Model Training     | scikit-learn        |
| API                | FastAPI             |
| Experiment Tracking| MLflow              |
| Containerization   | Docker              |
| CI/CD              | GitHub Actions + Railway |
| Hosting            | Railway (free)      |

---

## Folder Structure

```
customer-churn-mlops/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ main.yml         # GitHub Action
â”œâ”€â”€ data/                    # Dataset (local only)
â”œâ”€â”€ models/                  # Trained model files (.pkl)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api.py               # FastAPI app
â”‚   â”œâ”€â”€ train.py             # Training script
â”‚   â””â”€â”€ preprocess.py        # Data transformation
â”œâ”€â”€ Dockerfile               # Docker container definition
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md
```

---

## Setup Instructions

### 1. Create and activate virtual environment
```bash
python -m venv venv
.\venv\Scripts\activate
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Train the model
```bash
python -m src.train
```
- Saves: `model.pkl`, `scaler.pkl`, `encoder.pkl`, `columns.pkl`
- Logs experiment via **MLflow**

### 4. (Optional) View MLflow experiment tracking
```bash
mlflow ui
```
Open in browser: [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

### 5. Run the API Server

```bash
uvicorn src.api:app --reload
```

Visit Swagger UI: [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)  
Use the `/predict` endpoint to send customer data and receive churn prediction!

---

## Sample Input (for `/predict`)

```json
{
  "gender": "Female",
  "SeniorCitizen": 1,
  "Partner": "No",
  "Dependents": "No",
  "tenure": 1,
  "PhoneService": "Yes",
  "MultipleLines": "Yes",
  "InternetService": "Fiber optic",
  "OnlineSecurity": "No",
  "OnlineBackup": "No",
  "DeviceProtection": "No",
  "TechSupport": "No",
  "StreamingTV": "Yes",
  "StreamingMovies": "Yes",
  "Contract": "Month-to-month",
  "PaperlessBilling": "Yes",
  "PaymentMethod": "Electronic check",
  "MonthlyCharges": 95.0,
  "TotalCharges": 95.0
}
```

Expected result:
```json
{
  "churn_prediction": 1,
  "churn_probability": 0.92
}
```

---

## GitHub Actions (CI)

This project uses GitHub Actions to automatically:
- Install dependencies
- Run the training pipeline on every push to `main`
- Log the model to MLflow

You can find the workflow in `.github/workflows/main.yml`.

---

## ğŸŒ Deployment (CD)

- Public URL: `https://customer-churn-mlops-production.up.railway.app/docs`
- Triggered automatically on **push to GitHub**
- **No manual deploy button required** on Railway

---

## Notes

- Model files (`.pkl`) are generated after running `train.py`
- The pipeline can be extended with GitHub Actions and Docker for full CI/CD

---